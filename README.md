# Tree-and-Forest
# Titanic Survival Prediction

This repository contains a Jupyter Notebook that demonstrates the use of decision tree and ensemble methods (bagging, random forest, and boosting) to predict the survival of passengers on the Titanic.

## Dataset

The dataset used is the Titanic dataset, which can be found on [Kaggle](https://www.kaggle.com/c/titanic/data). It includes information about the passengers on the Titanic, such as their age, sex, ticket class, and whether they survived or not.

## Methods

The following prediction methods are demonstrated in the notebook:

1. **Decision Tree**
2. **Bagging**
3. **Random Forest**
4. **Boosting**
5. **Grid search with different hyperparaemeter to determine the best parameters, best model, and best accuracy.
6. **accuracy
7. **most important feature.

Analysis and Results

Data Preprocessing
Load the Titanic dataset using pandas.
Handle missing values and encode categorical variables.
Split the data into training and test sets.
Decision Tree
Train a decision tree classifier.
Visualize the decision tree.
Bagging
Train a bagging classifier.
Evaluate the accuracy.
Random Forest
Train a random forest classifier.
Determine feature importance.
Tune the parameters n_estimators and max_depth.
Evaluate the accuracy.
Boosting
Train a boosting classifier.
Tune the parameters n_estimators and max_depth.
Evaluate the accuracy on the development set.
Model Comparison
Compare the accuracy of all models on the test sets.
Determine which model performed the best.
Conclusion

This notebook demonstrates how to use decision trees and ensemble methods to predict the survival of Titanic passengers. It also highlights the importance of model tuning and comparison to achieve the best performance.

Author

@davidenendu
License

This project is licensed under the MIT License - see the LICENSE file for details.




